{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center> FUNDAMENTOS DE APRENDIZAJE AUTOMÁTICO <br> Y RECONOCIMIENTO DE PATRONES</center>\n",
    "## <center> 2do parcial, 2021</center>           \n",
    "\n",
    "La duración del parcial es de 3 horas. El parcial consta de 3 ejercicios, cuya suma total es de 100 puntos. El parcial es sin material y no está permitido acceder a Internet. Ante cualquier duda comuníquese con los docentes. \n",
    "\n",
    "Este notebook corresponde al **ejercicio 2**. Hay un notebook por ejercicio planteado.\n",
    "\n",
    "\n",
    "* [Ejercicio 2 - GMM](#Ejercicio2) (35 puntos)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importar bibliotecas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se importan las bibliotecas que se utilizarán\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.mixture import GaussianMixture as GMM\n",
    "from sklearn.metrics import pairwise_distances\n",
    "from sklearn.datasets import load_digits\n",
    "\n",
    "from scipy.stats import multivariate_normal\n",
    "\n",
    "from fuaa_utils_ej2 import evaluar_kernel_gaussiano\n",
    "from fuaa_utils_ej2 import generar_datos\n",
    "from fuaa_utils_ej2 import generar_muestras_gaussiana_multivariada\n",
    "from fuaa_utils_ej2 import identificar_parcial\n",
    "from fuaa_utils_ej2 import inicializar_mezcla\n",
    "from fuaa_utils_ej2 import log_verosimilitud\n",
    "from fuaa_utils_ej2 import maximization_step\n",
    "from fuaa_utils_ej2 import plot_digits\n",
    "from fuaa_utils_ej2 import plot_gmm\n",
    "from fuaa_utils_ej2 import plot_scatter\n",
    "from fuaa_utils_ej2 import validar_resultado\n",
    "\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (10, 10)\n",
    "\n",
    "identificar_parcial()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UFdyo6hAqq1V"
   },
   "source": [
    "<a id=\"Ejercicio2\"></a>\n",
    "# Modelos de Mezclas de Gaussianas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UFdyo6hAqq1V"
   },
   "source": [
    "Un Modelo de Mezcla Gaussianas (GMM) intenta encontrar una mezcla de distribuciones de probabilidad gaussianas multidimensionales que modelen un conjunto de datos de entrada. En el caso más sencillo, los GMM pueden utilizarse para encontrar clusters de la misma forma que con *k*-means.\n",
    "\n",
    "El objetivo de la primera parte de este ejercicio es evaluar el ajuste de modelos de Mezcla de Gaussianas. Los parámetros se estimarán mediante la implementación de un esquema de Expectation-Maximization (EM) para encontrar los parámetros que maximizan la verosimilitud del modelo Mezcla de Gaussianas para un conjunto de datos $X$. \n",
    "\n",
    "Si se utilizan ${N_g}$ componentes en la mezcla, el modelo está dado por:\n",
    "$$p(\\mathbf{x_n|\\Theta})=\\sum_{j=1}^{N_g} w_j \\mathcal{N}\\left( \\mathbf{x_n} \\vert \\mathbf{\\mu_j},\\mathbf{\\Sigma_j} \\right)$$ donde $\\mathcal{N}$ es una Gaussiana, $w_i$, $\\mu_i$ y $\\Sigma_i$ son, respectivamente, el peso en la mezcla, la media y la matriz de covarianza de la $i$-ésima Gaussiana, y $\\Theta$ representa los parámetros de la mezcla.\n",
    "\n",
    "Se implementarán funciones utilizando el esquema EM para encontrar los parámetros óptimos en el caso de Mezcla de Gaussianas. El esquema sigue los siguientes pasos:\n",
    "\n",
    "- Inicialización\n",
    "- Loop donde se calculan:\n",
    "    - *Expectation Step* (Parte (a))\n",
    "    - *Maximization Step* \n",
    "    - Se evalúa condición de continuidad en el loop (Parte (b))\n",
    "- Ajuste de GMM a datos sintéticos (Parte (c))\n",
    "- Análisis cualitativo de los ajustes (Parte (d))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generación y visualización de los datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se generan y visualizan datos sintéticos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "20erb8Wnqq1X"
   },
   "outputs": [],
   "source": [
    "# Generar datos.\n",
    "X = generar_datos()\n",
    "plot_scatter(X[:, 0], X[:, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inicialización"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se provee la función `inicializar_mezcla()` que es la encargada de inicializar las medias $\\mathbf{\\mu_j}$, las covarianzas $\\mathbf{\\Sigma_j}$ y los coeficientes $\\mathbf{w}$ de la mezcla . La inicialización de los $\\mathbf{\\mu_j}$ es como ${k}$ vectores de $X$ elegidos aleatoriamente. \n",
    "\n",
    "La función `inicializar_mezcla()` tiene la siguiente definición:\n",
    "<pre>\n",
    "def inicializar_mezcla(X, Ng, semilla):\n",
    "    '''\n",
    "    Entrada:\n",
    "        X: matriz de tamaño (N,d) que contiene N muestras, una por fila.\n",
    "        Ng: número de clusters a encontrar.\n",
    "    Salida:\n",
    "        w: arreglo de largo Ng que contiene los pesos de la mezcla. \n",
    "           Se deben inicializar a valores aleatorios cuya suma sea 1.\n",
    "        mus: arreglo de tamaño (Ng,d) que contiene los pesos.\n",
    "        sigmas: arreglo de tamaño (Ng,d,d) que contiene las matrices de \n",
    "                covarianza de los clusters\n",
    "    '''\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parte (a): Expectation step"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implementar `expectation_step()`. Se calcula la probabilidad de que la *n-ésima* muestra haya sido generada por la componente *j-ésima* de la mezcla. Para ello se utilizan los parámetros actuales   \n",
    "\n",
    "$$\n",
    "\\gamma_{nj} = \\frac{w_j \\mathcal{N}\\left( \\mathbf{x_n} \\vert \\mathbf{\\mu_j},\\mathbf{\\Sigma_j} \\right)}{\\sum_{l=1}^{L} w_l \\mathcal{N}\\left( \\mathbf{x_n} \\vert \\mathbf{\\mu_l},\\mathbf{\\Sigma_l} \\right)} \n",
    "$$\n",
    "\n",
    "**Sugerencia:** Para la evaluación de una Gaussiana en un punto se sugiere analizar el método `multivariate_normal.pdf()` de `scipy.stats` que ya fue importado y está disponible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def expectation_step(X, w, mus, sigmas):\n",
    "    '''\n",
    "    Entrada:\n",
    "        X: matriz de tamaño Nxd con las muestras a evaluar.\n",
    "        w: vector de largo k que contiene los pesos de la mezcla. \n",
    "        mus: arreglo de tamaño (k,d) que contiene las k medias.\n",
    "        sigmas: arreglo de tamaño (k,d,d) que contiene las matrices de \n",
    "                covarianza de los clusters.\n",
    "    Salida:\n",
    "        gammas: matriz de tamaño Nxk con las probabilidades de pertenencia a \n",
    "                cada cluster.\n",
    "    '''\n",
    "    \n",
    "    multivariate_normal()\n",
    "\n",
    "    N, d = X.shape\n",
    "    k = len(w)\n",
    "    \n",
    "    #####################################################\n",
    "    ####### EMPIEZA ESPACIO PARA COMPLETAR CODIGO #######\n",
    "    #####################################################\n",
    "\n",
    "    \n",
    "    # gammas =\n",
    "\n",
    "    \n",
    "    #####################################################\n",
    "    ####### TERMINA ESPACIO PARA COMPLETAR CODIGO #######\n",
    "    #####################################################\n",
    "\n",
    "    return gammas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se testea expectation_step()\n",
    "validar_resultado('expectation_step', funcion=expectation_step)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Maximization step"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se provee la función `maximization_step()`. Se encuentran los parámetros óptimos utilizando la distribución de $\\gamma_{nj}$ actual\n",
    "\\begin{align*}\n",
    "&N_j                       = \\sum_{n=1}^{N}\\gamma_{nj} \\\\\n",
    "&\\mathbf{\\mu_j^{new}}      = \\frac{1}{N_j}\\sum_{n=1}^{N}\\gamma_{nj}\\mathbf{x_n}  \\\\\n",
    "&\\mathbf{\\Sigma_j^{new}}   = \\frac{1}{N_j}\\sum_{n=1}^{N}\\gamma_{nj}\\left(\\mathbf{x_n}-\\mathbf{\\mu_j}\\right)\\left(\\mathbf{x_n}-\\mathbf{\\mu_j}\\right)^T  \\\\\n",
    "&w_j^{new}               = \\frac{N_j}{N} \\\\\n",
    "\\end{align*}\n",
    "La función `maximization_step()` tiene la siguiente definición:\n",
    "<pre>\n",
    "def maximization_step(X, gammas):\n",
    "    '''\n",
    "    Entrada:\n",
    "        X: matriz de tamaño Nxd con las muestras a evaluar.\n",
    "        gammas: arreglo de tamaño (N,k) con las probabilidades de pertenencia \n",
    "                a cada cluster.\n",
    "        \n",
    "    Salida:\n",
    "        w: vector de pesos de la mezcla.\n",
    "        mus: arreglo de tamaño (k,d) que contiene las medias en el paso \n",
    "             actual.\n",
    "        sigmas: arreglo de tamaño (k,d,d) que contiene las matrices de \n",
    "                covarianza de los clusters en el paso actual.    \n",
    "    '''\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parte (b): Loop EM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Completar la implementación de `gmm_EM`. Para ello utilizar las implementaciones de las partes anteriores de forma de maximizar la verosimilitud del modelo.\n",
    "\n",
    "Para el cálculo de la verosimilitud se puede utilizar la función `log_verosimilitud()` que tiene la siguiente definición:\n",
    "\n",
    "<pre>\n",
    "def log_verosimilitud(X, w, mus, sigmas):\n",
    "    '''\n",
    "    Entrada:\n",
    "        X: matriz de tamaño Nxd que contiene las muestras.\n",
    "        w: arreglo de tamaño k que contiene los pesos actuales.\n",
    "        mus: arreglo de tamaño (k,d) que contiene las medias, una por fila.\n",
    "        sigmas: arreglo de tamaño (k,d,d) que contiene las matrices de covarianza.\n",
    "     Salida:\n",
    "        log_ver: logaritmo de la verosimilitud de las muestras con el modelo.\n",
    "    '''\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gmm_EM(X, Ng, tol=0.01, max_iter=100, semilla=2):\n",
    "    '''\n",
    "    Entrada:\n",
    "        X: matriz de tamaño Nxd que contiene N muestras, una por fila\n",
    "        Ng: número de componentes.\n",
    "        tol: si la log verosimilitud en el paso actual no mejora al menos \n",
    "             <tol> respecto a la del paso anterior se termina la optimización.\n",
    "        max_iter: máximo número de iteraciones en la optimización.\n",
    "        semilla: semilla a utilizar en la inicialización de las gaussianas.\n",
    "        \n",
    "    Salida:\n",
    "        gmm: Diccionario con las siguientes claves:\n",
    "            log_ver: lista que almacena las log-verosimilitudes calculadas \n",
    "                     durante la optimización.\n",
    "            probs: matriz de tamaño Nxk con las probabilidades de pertenencia \n",
    "                   a cada cluster.\n",
    "            weights: vector de tamaño k que contiene los pesos estimados.\n",
    "            means: matriz de tamaño (k,d) que contiene las medias, una por \n",
    "                   fila.\n",
    "            covars: arreglo de tamaño (k,d,d) que contiene las matrices de \n",
    "                    covarianza.\n",
    "    '''\n",
    "    N, d = X.shape\n",
    "    \n",
    "    w, mus, sigmas = inicializar_mezcla(X, Ng, semilla)\n",
    "    w0, mus0, sigmas0 = w, mus, sigmas\n",
    "    \n",
    "    log_ver_previa = -np.infty\n",
    "    log_ver = []  # Almacena las log-verosimilitudes durante la optimización.\n",
    "\n",
    "    termino = False\n",
    "    n_iter = 0\n",
    "    print('+------+-------------------+')\n",
    "    print('| iter | log verosimilitud |')\n",
    "    print('+------+-------------------+')\n",
    "    while not termino:\n",
    "\n",
    "        #####################################################\n",
    "        ####### EMPIEZA ESPACIO PARA COMPLETAR CODIGO #######\n",
    "        #####################################################\n",
    "\n",
    "        # E-step\n",
    "        # probs = \n",
    "\n",
    "       \n",
    "        # M-step\n",
    "        # w, mus, sigmas =\n",
    "\n",
    "        \n",
    "        # se actualiza la log verosimilitud\n",
    "        # log_ver_actual =\n",
    "\n",
    "        \n",
    "        # se evalúa condición de terminación (dos condiciones)\n",
    "        # termino =\n",
    "        \n",
    "        \n",
    "        #####################################################\n",
    "        ####### TERMINA ESPACIO PARA COMPLETAR CODIGO #######\n",
    "        #####################################################\n",
    "\n",
    "        log_ver.append(log_ver_actual)\n",
    "        log_ver_previa = log_ver_actual\n",
    "        n_iter += 1\n",
    "        print('| %3d  |      %8.2f     |' % (n_iter, log_ver_actual))\n",
    "\n",
    "    print('+------+-------------------+')\n",
    "\n",
    "    gmm = {\n",
    "        \"log_ver\": log_ver,\n",
    "        \"means\": mus,\n",
    "        \"covars\": sigmas,\n",
    "        \"weights\": w,\n",
    "        \"probs\": probs\n",
    "    }\n",
    "    \n",
    "    return gmm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parte (c): Ajuste modelo GMM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Realizar el ajuste de un modelo GMM a los datos en `X` con `Ng` gaussianas, variando `Ng` entre 2 y 6, inclusive. Completar una tabla como la siguiente:\n",
    "\n",
    "| Número de componentes | Log verosimilitud | Número de iteraciones |\n",
    "| --- | --- | --- |\n",
    "| 2 |  |  |\n",
    "| ... |  |  |\n",
    "| 6 |  |  |\n",
    "\n",
    "\n",
    "Para la clasificación se le asigna a cada elemento de `X` como etiqueta un entero entre 0 y Ng-1 correspondiente al índice de la Gaussiana que le asigna mayor probabilidad."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for k in range(2, 7):\n",
    "    print('Ajuste de GMM con %d gaussianas.' % k)\n",
    "\n",
    "    #####################################################\n",
    "    ####### EMPIEZA ESPACIO PARA COMPLETAR CODIGO #######\n",
    "    #####################################################\n",
    "\n",
    "    # Ajustar modelo GMM a X.\n",
    "    # gmm1 = \n",
    "\n",
    "\n",
    "    # Calcular la etiqueta (un entero entre 0 y k-1) para cada elemento de X.\n",
    "    # labels_gmm = \n",
    "\n",
    "\n",
    "    #####################################################\n",
    "    ####### TERMINA ESPACIO PARA COMPLETAR CODIGO #######\n",
    "    #####################################################\n",
    "    plot_gmm(X, gmm1, labels_gmm)\n",
    "    plt.title('Ajuste de GMM con %d gaussianas' % k )\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parte (d): Análisis de los ajustes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Teniendo en cuenta los resultados cualitativos y la tabla armada en la parte anterior variando el número de componentes (Gaussianas) ¿cuál sería el número de componentes a utilizar?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Respuesta:** ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WsmgHYQ6qq1g"
   },
   "source": [
    "# GMM como un estimador de densidad\n",
    "\n",
    "Además de ser un algotirmo de clustering, GMM es fundamentalmente un algoritmo de *estimación de la densidad*.\n",
    "Es decir, el resultado del ajuste de un GMM a unos datos es un modelo probabilístico que describe la su distribución.\n",
    "\n",
    "En esta parte del ejercicio evaluaremos cómo utilizar un GMM para generar nuevos datos a partir del modelo entrenado. El esquema que se sigue es el siguiente:\n",
    "\n",
    "- Generación de nuevas muestras (Parte (g))\n",
    "- Comparar el modelo ajustado a las nuesvas muestras con el modelo original (Parte (h))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parte (e): Generar nuevas muestras de GMM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Completar la función `generar_muestras_gmm`. La función debe generar `Nm` puntos distribuidos según el modelos `gmm`. \n",
    "\n",
    "Puede ser de utilidad la función `generar_muestras_gaussiana_multivariada()` con la siguiente definición:\n",
    "<pre>\n",
    "def generar_muestras_gaussiana_multivariada(mean_, Sigma_, N=100):\n",
    "    '''\n",
    "    Función para generar N muestras de una Gaussiana multivariada de dimensión\n",
    "    d usando la descomposición de Cholesky.\n",
    "    \n",
    "    Entrada: \n",
    "        mean_: Arreglo de tamaño (1,d) que contiene la media.\n",
    "        Sigma_: Arreglo de tamaño (dxd) que contiene la matriz de covarianza.\n",
    "        n: Número de puntos a generar.\n",
    "        \n",
    "    Salida: \n",
    "        X: Arreglo de tamaño (Nxd).\n",
    "    '''\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generar_muestras_gmm(gmm, Nm=100):\n",
    "    '''\n",
    "    Entrada:\n",
    "        gmm: Modelos de Mezcla de Gaussianas como un diccionario generado por \n",
    "             la función gmm_EM().\n",
    "        Nm: Número de nuevas muestras a generar.\n",
    "\n",
    "    Salida:\n",
    "        Xgen: Matriz de tamaño Nmxd con los datos generados.\n",
    "    '''\n",
    "\n",
    "    # Obtener el número de componentes del GMM y la dimensión de los datos.\n",
    "    Ng = gmm['means'].shape[0]\n",
    "    d = gmm['means'][0].shape[0]\n",
    "\n",
    "    # Calcular el número de datos de cada componente, Ns (vector de tamaño Ng).\n",
    "    Ns = np.around(Nm * gmm['weights']).astype(int)\n",
    "    \n",
    "    #####################################################\n",
    "    ####### EMPIEZA ESPACIO PARA COMPLETAR CODIGO #######\n",
    "    #####################################################\n",
    "    \n",
    "    # Generar Nm datos a partir de la generación de Ns[i] datos para cada \n",
    "    # una de las Ng componentes (0 <= i < Ng).\n",
    "    # Xgen = \n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    #####################################################\n",
    "    ####### EMPIEZA ESPACIO PARA COMPLETAR CODIGO #######\n",
    "    #####################################################\n",
    "\n",
    "    return Xgen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Primero se ajusta un modelo GMM `gmm_org` con $N_g=4$ a los datos de trabajo. Luego se generarán nuevas muestras con este modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ajustar modelo GMM con Ng=4.\n",
    "gmm_org = gmm_EM(X, Ng=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se generan $N_m=400$ muestras con el método `generar_muestras_gmm` implementado y el modelo `gmm_org` recién ajustado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Nm = 400\n",
    "Xgen = generar_muestras_gmm(gmm_org, Nm=Nm)\n",
    "plot_scatter(Xgen[:, 0], Xgen[:, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parte (f): Comparar GMM de datos generados y originales"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En esta sección se hace un ajuste de un modelo GMM a los datos generados `Xgen`. El objetivo es comparar los parámetros obtenidos en el ajuste con los del modelo GMM original. Si los datos generados cumplen con los parámetros del modelo de entrada, los parámetros del modelo de salida deben ser similares."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ajustar modelo GMM a los datos generados.\n",
    "gmm_gen = gmm_EM(Xgen, Ng=4, semilla=42)\n",
    "\n",
    "# Visualizar el ajuste.\n",
    "labels_gmm_gen = np.argmax(gmm_gen['probs'], axis=1)\n",
    "plot_gmm(Xgen, gmm_gen, labels_gmm_gen)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": false
   },
   "source": [
    "A modo de verificación se muestran los centro de las Gaussianas obtenidas en el modelo `gmm_gen` con el original `gmm_org`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Centros de gaussianas del modelo original:')\n",
    "print(gmm_org['means'])\n",
    "print('\\nCentros de gaussianas del modelo original:')\n",
    "print(gmm_gen['means'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Las componentes no tienen que quedar en el mismo orden en ambos modelos. Para cuantificar automáticamente la distancia entre los centros de las Gaussianas primero se ordenan por la primera coordenada (en este caso es suficiente). Completar la siguiente celda para calcular las distancias entre estos centros, y la diferencia en los pesos calculados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ordenar los centros de las gaussianas según la primera coordenada. Se\n",
    "# almacenan los índices para ordenar los centros.\n",
    "sorted_ind_gmm_org = np.argsort(gmm_org['means'][:, 0])\n",
    "sorted_ind_gmm_gen = np.argsort(gmm_gen['means'][:, 0])\n",
    "\n",
    "#####################################################\n",
    "####### EMPIEZA ESPACIO PARA COMPLETAR CODIGO #######\n",
    "#####################################################\n",
    "\n",
    "# Calcular las distancias entre los centros de las gaussianas a partir del\n",
    "# ordenamiento obtenido.\n",
    "# distancia_entre_componentes =\n",
    "\n",
    "\n",
    "\n",
    "# Calcular el error entre los pesos de las gaussianas a partir del\n",
    "# ordenamiento obtenido.\n",
    "# error_pesos_componentes =\n",
    "\n",
    "\n",
    "\n",
    "#####################################################\n",
    "####### TERMINA ESPACIO PARA COMPLETAR CODIGO #######\n",
    "#####################################################\n",
    "\n",
    "print('Distancia entre centros de las Gaussianas:')\n",
    "print(np.array_str(distancia_entre_componentes, precision=2, suppress_small=False))\n",
    "\n",
    "print('\\nError en pesos de las Gaussianas:')\n",
    "print(np.array_str(error_pesos_componentes, precision=2, suppress_small=False))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generación de datos sintéticos como muestras de un modelo aprendido"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En esta parte del ejercicio se evaluará la generación de datos sintéticos como muestras de un modelo GMM aprendido. Se utilizará la implementación de GMM disponible en la biblioteca scikit-learn.\n",
    "\n",
    "Se cargan un conjunto de imágenes de dígitos. Cada imagen de 8x8 píxeles se considera como un dato de dimensión 64. Se ajusta un modelo GMM a este conjunto de datos variando el número de componentes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargan los datos de dígitos, se muestran sus dimensiones y 100 de ellos.\n",
    "digitos = load_digits()\n",
    "print('Son %d dígitos de dimensión %d cada uno.' %\n",
    "      (digitos.data.shape[0], digitos.data.shape[1]))\n",
    "plot_digits(digitos.data, title='Dígitos originales (de 8x8 píxeles)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se generan $Nm=100$ muestras de estos modelos GMM y se muestran las correspondientes imágenes sintéticas (no son datos reales tomados de los dígitos)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Nm = 100\n",
    "for Ng in 1, 10, 100:\n",
    "\n",
    "    # Se ajusta un modelo GMM con <Ng> componentes a los datos.\n",
    "    gmm = GMM(Ng, covariance_type='full', random_state=0)\n",
    "    gmm.fit(digitos.data)\n",
    "\n",
    "    # Se generan Nm nuevos datos sorteados del modelo GMM ajustado.\n",
    "    digitos_new = gmm.sample(Nm)\n",
    "\n",
    "    # Visualizar los datos sintéticos generados.\n",
    "    plot_digits(digitos_new[0], title='Dígitos generados con GMM de %d componentes' % Ng)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parte (g): Evaluación de los datos generados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comparar cualitativamente los conjuntos de números generados a partir de los modelos variando el número de componentes. ¿Cómo se explica esta calidad respecto a la cantidad de componentes del modelo GMM en cada caso?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Respuesta:** ..."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "05.12-Gaussian-Mixtures.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "381.917px",
    "left": "60px",
    "top": "111.133px",
    "width": "263px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "oldHeight": 434.85,
   "position": {
    "height": "40px",
    "left": "712px",
    "right": "20px",
    "top": "16px",
    "width": "555px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "varInspector_section_display": "none",
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
